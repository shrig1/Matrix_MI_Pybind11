{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from scipy.sparse import issparse\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.sparse import csr_matrix\n",
    "import time\n",
    "\n",
    "def mutual_information_matrix_serial(matrix, nbins=20, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Computes the mutual information matrix in parallel, working directly with sparse matrices,\n",
    "    and only computes the upper triangular part of the matrix.\n",
    "    \"\"\"\n",
    "    if not issparse(matrix):\n",
    "        matrix = csr_matrix(matrix)\n",
    "\n",
    "    n_features = matrix.shape[0]\n",
    "    mi_matrix = np.zeros((n_features, n_features))\n",
    "\n",
    "    def compute_pairwise_mi(vi, vj, nbins=20):\n",
    "        joint_counts, _, _ = np.histogram2d(vi, vj, bins=nbins)\n",
    "        ncounts = joint_counts.sum()\n",
    "        if ncounts == 0:\n",
    "            return 0  # No mutual information if no overlap\n",
    "        joint_prob = joint_counts / ncounts\n",
    "\n",
    "        marginal_i = joint_prob.sum(axis=1) + 1e-10\n",
    "        marginal_j = joint_prob.sum(axis=0) + 1e-10\n",
    "\n",
    "        h_xy = entropy(joint_prob.flatten(), base=2)\n",
    "        h_x = entropy(marginal_i, base=2)\n",
    "        h_y = entropy(marginal_j, base=2)\n",
    "\n",
    "        return float(h_x + h_y - h_xy)\n",
    "\n",
    "    for i in range(n_features):\n",
    "        for j in range(i, n_features):\n",
    "            vi = matrix[i, :].toarray().flatten()\n",
    "            vj = matrix[j, :].toarray().flatten()\n",
    "            mi_matrix[i, j] = compute_pairwise_mi(vi, vj, nbins=nbins)\n",
    "            if i != j:\n",
    "                mi_matrix[j, i] = mi_matrix[i, j]  # Exploit symmetry\n",
    "    return mi_matrix\n",
    "\n",
    "def mutual_information_matrix_parallel(matrix, nbins=20, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Computes the mutual information matrix in parallel, working directly with sparse matrices,\n",
    "    and computes the full matrix (including the diagonal elements).\n",
    "    \"\"\"\n",
    "    if not issparse(matrix):\n",
    "        matrix = csr_matrix(matrix)\n",
    "\n",
    "    n_features = matrix.shape[0]\n",
    "    mi_matrix = np.zeros((n_features, n_features))\n",
    "\n",
    "    def compute_pairwise_mi(i, j, matrix, nbins=20):\n",
    "        \"\"\"\n",
    "        Computes mutual information between row i and row j of the sparse matrix.\n",
    "        \"\"\"\n",
    "        vi = matrix[i, :].toarray().flatten()\n",
    "        vj = matrix[j, :].toarray().flatten()\n",
    "        \n",
    "        joint_counts, _, _ = np.histogram2d(vi, vj, bins=nbins)\n",
    "        ncounts = joint_counts.sum()\n",
    "        if ncounts == 0:\n",
    "            return 0  # No mutual information if no overlap\n",
    "        joint_prob = joint_counts / ncounts\n",
    "\n",
    "        marginal_i = joint_prob.sum(axis=1) + 1e-10\n",
    "        marginal_j = joint_prob.sum(axis=0) + 1e-10\n",
    "\n",
    "        h_xy = entropy(joint_prob.flatten(), base=2)\n",
    "        h_x = entropy(marginal_i, base=2)\n",
    "        h_y = entropy(marginal_j, base=2)\n",
    "\n",
    "        return float(h_x + h_y - h_xy)\n",
    "\n",
    "    # Parallelizing the pairwise mutual information computation\n",
    "    jobs = [(i, j) for i in range(n_features) for j in range(i, n_features)]  # Includes diagonal\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(compute_pairwise_mi)(i, j, matrix, nbins) for i, j in jobs\n",
    "    )\n",
    "\n",
    "    # Fill the matrix with the results\n",
    "    for idx, (i, j) in enumerate(jobs):\n",
    "        mi_matrix[i, j] = results[idx]\n",
    "        mi_matrix[j, i] = results[idx]  # Exploit symmetry to avoid duplicate computation\n",
    "\n",
    "    return mi_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from joblib import Parallel, delayed\n",
    " \n",
    "def mutual_information_matrix_df(df, bins=20, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Computes the mutual information matrix using NumPy's vectorized operations and parallel processing.\n",
    " \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        n_jobs (int, optional): Number of jobs for parallel processing. Defaults to 4.\n",
    " \n",
    "    Returns:\n",
    "        np.ndarray: Mutual information matrix.\n",
    "    \"\"\"\n",
    " \n",
    "    n_features = df.shape[1]\n",
    "    mi_matrix = np.zeros((n_features, n_features))\n",
    " \n",
    "    def compute_mi(i, j):\n",
    "        joint_prob = np.histogram2d(df.iloc[:, i], df.iloc[:, j], bins=bins)[0]\n",
    "        joint_prob /= joint_prob.sum() \n",
    " \n",
    "        marginal_prob_i = joint_prob.sum(axis=1)\n",
    "        marginal_prob_j = joint_prob.sum(axis=0)\n",
    " \n",
    "        mi = entropy(joint_prob.flatten(), base=2) - entropy(marginal_prob_i,base=2) - entropy(marginal_prob_j,base=2)\n",
    "        return mi\n",
    " \n",
    "    jobs = [(i, j) for i in range(n_features) for j in range(i + 1, n_features)]\n",
    "    results = Parallel(n_jobs=n_jobs)(delayed(compute_mi)(*job) for job in jobs)\n",
    " \n",
    "    for (i, j), mi in zip(jobs, results):\n",
    "        mi_matrix[i, j] = mi\n",
    "        mi_matrix[j, i] = mi\n",
    " \n",
    "    np.fill_diagonal(mi_matrix, 1)  # Self-information is always 1\n",
    " \n",
    "    return mi_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import random as sparse_random\n",
    "from scipy.io import mmwrite\n",
    "\n",
    "# Generate a sparse random matrix with 1000 rows and 5000 columns\n",
    "# Density of the matrix is set to 0.01 (1% non-zero elements)\n",
    "sparse_matrix = sparse_random(5000, 5000, density=0.01, format='csr')\n",
    "\n",
    "mmwrite(\"sparse_matrix.mtx\", sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dense_matrix = sparse_matrix.toarray().T  # Features as columns\n",
    "df = pd.DataFrame(dense_matrix)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "mi_matrix_df = mutual_information_matrix_df(df, bins=20, n_jobs=-1)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.4f} seconds\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 3042.1938 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "mi_matrix = mutual_information_matrix_parallel(sparse_matrix, nbins=20, n_jobs=-1)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.4f} seconds\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = [1, 2, 3, 0, 0]  # Row 0\n",
    "vec2 = [4, 0, 6, 0, 0]  # Row 1\n",
    "vec3 = [0, 1, 3, 7, 9]  # Row 2\n",
    "vec4 = [5, 0, 0, 0 ,2] # Row 3\n",
    "matrix = np.array([vec1, vec2, vec3, vec4])  # Use NumPy array for efficiency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.0317 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dense_matrix = matrix.T\n",
    "df = pd.DataFrame(dense_matrix)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "mi_matrix_df = mutual_information_matrix_df(df, bins=20, n_jobs=-1)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.4f} seconds\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.0316 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "mi_matrix = mutual_information_matrix_parallel(matrix, nbins=20, n_jobs=-1)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.4f} seconds\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.9219282 , 1.3709507 , 1.9219282 , 0.9709507 ],\n",
       "       [1.3709507 , 1.37095071, 1.3709507 , 0.81997321],\n",
       "       [1.9219282 , 1.3709507 , 2.32192819, 1.3709507 ],\n",
       "       [0.9709507 , 0.81997321, 1.3709507 , 1.37095071]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_matrix[0:4,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -1.37095059, -1.92192809, -0.97095059],\n",
       "       [-1.37095059,  1.        , -1.37095059, -0.81997309],\n",
       "       [-1.92192809, -1.37095059,  1.        , -1.37095059],\n",
       "       [-0.97095059, -0.81997309, -1.37095059,  1.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_matrix_df[0:4,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix_mi = csr_matrix(mi_matrix)\n",
    "print(sparse_matrix_mi)\n",
    "mmwrite(\"sparse_matrix_mi.mtx\", sparse_matrix_mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 4365.2635 seconds\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 25000000 stored elements and shape (5000, 5000)>\n",
      "  Coords\tValues\n",
      "  (0, 0)\t0.08595718539621552\n",
      "  (0, 1)\t8.695767045516223e-05\n",
      "  (0, 2)\t0.0001009282230546582\n",
      "  (0, 3)\t0.0021832049015041155\n",
      "  (0, 4)\t0.00010265814458118583\n",
      "  (0, 5)\t9.906287545818904e-05\n",
      "  (0, 6)\t0.00010296923787081469\n",
      "  (0, 7)\t0.00012718322926646985\n",
      "  (0, 8)\t0.00011097445947733098\n",
      "  (0, 9)\t0.00010094093701806806\n",
      "  (0, 10)\t0.0001068829646203584\n",
      "  (0, 11)\t9.042029584752087e-05\n",
      "  (0, 12)\t0.00011710334953562995\n",
      "  (0, 13)\t0.00012103499616814006\n",
      "  (0, 14)\t0.0017203431515214473\n",
      "  (0, 15)\t0.00011506174719264073\n",
      "  (0, 16)\t8.070379777949666e-05\n",
      "  (0, 17)\t0.0013403142832507375\n",
      "  (0, 18)\t7.867074161838072e-05\n",
      "  (0, 19)\t0.00011288742424414577\n",
      "  (0, 20)\t9.669157042743737e-05\n",
      "  (0, 21)\t8.228068031501667e-05\n",
      "  (0, 22)\t0.00011694402415221572\n",
      "  (0, 23)\t0.00012938554579056127\n",
      "  (0, 24)\t0.00013740750799048906\n",
      "  :\t:\n",
      "  (4999, 4975)\t0.00010613607554854632\n",
      "  (4999, 4976)\t9.773140312341333e-05\n",
      "  (4999, 4977)\t9.759342632167933e-05\n",
      "  (4999, 4978)\t0.001926634421942297\n",
      "  (4999, 4979)\t0.00011500066303513079\n",
      "  (4999, 4980)\t8.209277394891079e-05\n",
      "  (4999, 4981)\t0.00013958510116171552\n",
      "  (4999, 4982)\t9.285150789073437e-05\n",
      "  (4999, 4983)\t0.0017736195969704494\n",
      "  (4999, 4984)\t9.50510224546619e-05\n",
      "  (4999, 4985)\t0.0017669934481439331\n",
      "  (4999, 4986)\t9.978520508224786e-05\n",
      "  (4999, 4987)\t0.00011294943614426067\n",
      "  (4999, 4988)\t9.314550389663556e-05\n",
      "  (4999, 4989)\t0.0018966990631989478\n",
      "  (4999, 4990)\t0.00011515414048360317\n",
      "  (4999, 4991)\t0.0019246041149592608\n",
      "  (4999, 4992)\t0.0023030013518055004\n",
      "  (4999, 4993)\t0.00010628574925794498\n",
      "  (4999, 4994)\t0.0019031647456523304\n",
      "  (4999, 4995)\t0.0001262373891160462\n",
      "  (4999, 4996)\t0.0020496974137726998\n",
      "  (4999, 4997)\t0.00011278539186754255\n",
      "  (4999, 4998)\t7.799431583443983e-05\n",
      "  (4999, 4999)\t0.09540805619962546\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "mi_matrix = mutual_information_matrix_parallel(sparse_matrix, nbins=20, n_jobs=-1)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.4f} seconds\") \n",
    "\n",
    "sparse_matrix_mi = csr_matrix(mi_matrix)\n",
    "print(sparse_matrix_mi)\n",
    "mmwrite(\"sparse_matrix_mi.mtx\", sparse_matrix_mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 500)\n"
     ]
    }
   ],
   "source": [
    "print(mi_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced C++ integration with file I/O\n",
    "import subprocess\n",
    "import os\n",
    "from scipy.io import mmread, mmwrite\n",
    "\n",
    "def compute_mi_cpp_optimized(sparse_matrix, method=\"openmp\", num_threads=None):\n",
    "    \"\"\"\n",
    "    Compute mutual information using C++ implementation and return results to Python\n",
    "    \n",
    "    Args:\n",
    "        sparse_matrix: Input sparse matrix\n",
    "        method: \"openmp\" or \"serial\"\n",
    "        num_threads: Number of threads for OpenMP (None for auto)\n",
    "    \n",
    "    Returns:\n",
    "        MI matrix as numpy array\n",
    "    \"\"\"\n",
    "    # Save input matrix\n",
    "    mmwrite(\"sparse_matrix.mtx\", sparse_matrix)\n",
    "    \n",
    "    # Choose executable\n",
    "    executable = f\"./mi_{method}\"\n",
    "    if not os.path.exists(executable):\n",
    "        raise FileNotFoundError(f\"C++ executable {executable} not found. Please compile first.\")\n",
    "    \n",
    "    # Run C++ program\n",
    "    cmd = [executable]\n",
    "    if method == \"openmp\" and num_threads:\n",
    "        cmd.append(str(num_threads))\n",
    "    \n",
    "    print(f\"Running C++ computation with {method} method...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode != 0:\n",
    "        raise RuntimeError(f\"C++ execution failed: {result.stderr}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"C++ execution time: {end_time - start_time:.4f} seconds\")\n",
    "    print(\"C++ output:\", result.stdout)\n",
    "    \n",
    "    # Read results\n",
    "    if os.path.exists(\"sparse_matrix_mi.mtx\"):\n",
    "        mi_sparse = mmread(\"sparse_matrix_mi.mtx\")\n",
    "        return mi_sparse.toarray()\n",
    "    else:\n",
    "        raise FileNotFoundError(\"C++ did not generate output file\")\n",
    "\n",
    "# Example usage\n",
    "# mi_result = compute_mi_cpp_optimized(sparse_matrix, method=\"openmp\", num_threads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary format for faster I/O\n",
    "import struct\n",
    "\n",
    "def write_binary_matrix(matrix, filename):\n",
    "    \"\"\"Write matrix in binary format for C++ consumption\"\"\"\n",
    "    if issparse(matrix):\n",
    "        matrix = matrix.toarray()\n",
    "    \n",
    "    rows, cols = matrix.shape\n",
    "    with open(filename, 'wb') as f:\n",
    "        # Write header: rows, cols\n",
    "        f.write(struct.pack('ii', rows, cols))\n",
    "        # Write data as doubles\n",
    "        matrix.astype(np.float64).tobytes()\n",
    "        f.write(matrix.tobytes())\n",
    "\n",
    "def read_binary_matrix(filename):\n",
    "    \"\"\"Read binary matrix from C++ output\"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Read header\n",
    "        rows, cols = struct.unpack('ii', f.read(8))\n",
    "        # Read data\n",
    "        data = f.read(rows * cols * 8)  # 8 bytes per double\n",
    "        matrix = np.frombuffer(data, dtype=np.float64)\n",
    "        return matrix.reshape(rows, cols)\n",
    "\n",
    "def compute_mi_cpp_binary(sparse_matrix, method=\"openmp\", num_threads=None):\n",
    "    \"\"\"Fast binary I/O version\"\"\"\n",
    "    # Write input in binary format\n",
    "    write_binary_matrix(sparse_matrix, \"input_matrix.bin\")\n",
    "    \n",
    "    # Run C++ (would need to modify C++ to handle binary I/O)\n",
    "    executable = f\"./mi_{method}_binary\"  # Modified version\n",
    "    cmd = [executable]\n",
    "    if method == \"openmp\" and num_threads:\n",
    "        cmd.append(str(num_threads))\n",
    "    \n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode != 0:\n",
    "        raise RuntimeError(f\"C++ execution failed: {result.stderr}\")\n",
    "    \n",
    "    # Read binary output\n",
    "    return read_binary_matrix(\"output_mi.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 3: Python C Extension approach\n",
    "# This would require creating a pybind11 wrapper\n",
    "\n",
    "# Example of how it would look (after creating the extension):\n",
    "\n",
    "import py_mi_openmp  # Compiled C++ extension\n",
    "\n",
    "def compute_mi_native(sparse_matrix, method=\"openmp\", num_threads=8, nbins=20):\n",
    "    '''\n",
    "    Direct C++ function call from Python - no file I/O overhead\n",
    "    '''\n",
    "    if issparse(sparse_matrix):\n",
    "        # Convert to format expected by C++\n",
    "        matrix_array = sparse_matrix.toarray()\n",
    "    else:\n",
    "        matrix_array = sparse_matrix\n",
    "    \n",
    "    # Direct function call to C++ implementation\n",
    "    result = py_mi_openmp.run(\n",
    "        matrix_array, \n",
    "        nbins=nbins, \n",
    "        num_threads=num_threads,\n",
    "        use_openmp=(method==\"openmp\")\n",
    "    )\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Usage would be:\n",
    "mi_result = compute_mi_native(sparse_matrix, method=\"openmp\", num_threads=8)\n",
    "\n",
    "print(\"pybind11 extension would eliminate file I/O overhead completely\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 4: Shared Memory approach\n",
    "import mmap\n",
    "import tempfile\n",
    "\n",
    "def compute_mi_shared_memory(sparse_matrix, method=\"openmp\", num_threads=8):\n",
    "    \"\"\"\n",
    "    Use shared memory for zero-copy data transfer\n",
    "    \"\"\"\n",
    "    if issparse(sparse_matrix):\n",
    "        matrix = sparse_matrix.toarray()\n",
    "    else:\n",
    "        matrix = np.array(sparse_matrix)\n",
    "    \n",
    "    rows, cols = matrix.shape\n",
    "    \n",
    "    # Create shared memory files\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as input_file:\n",
    "        input_name = input_file.name\n",
    "        # Write matrix to shared memory\n",
    "        matrix.astype(np.float64).tofile(input_file)\n",
    "    \n",
    "    with tempfile.NamedTemporaryFile(delete=False) as output_file:\n",
    "        output_name = output_file.name\n",
    "    \n",
    "    # Run C++ with shared memory file paths\n",
    "    cmd = [f\"./mi_{method}_shared\", input_name, output_name, str(rows), str(cols)]\n",
    "    if num_threads:\n",
    "        cmd.append(str(num_threads))\n",
    "    \n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode != 0:\n",
    "        raise RuntimeError(f\"C++ execution failed: {result.stderr}\")\n",
    "    \n",
    "    # Read results from shared memory\n",
    "    result_matrix = np.fromfile(output_name, dtype=np.float64).reshape(rows, rows)\n",
    "    \n",
    "    # Cleanup\n",
    "    os.unlink(input_name)\n",
    "    os.unlink(output_name)\n",
    "    \n",
    "    return result_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to benchmark - uncomment the line below to run:\n",
      "Benchmarking different MI computation methods...\n",
      "Matrix size: (5000, 5000)\n",
      "Density: 0.0100\n",
      "--------------------------------------------------\n",
      "2. Testing C++ OpenMP with file I/O...\n",
      "Running C++ computation with openmp method...\n",
      "C++ execution time: 521.2266 seconds\n",
      "C++ output: Requested procs : 8\n",
      "Max procs available: 16\n",
      "Time taken for the parallel for loop: 513.12 seconds\n",
      "\n",
      "   Time: 522.1245 seconds\n",
      "   Speedup over Python: 5.83x\n",
      "C++ execution time: 521.2266 seconds\n",
      "C++ output: Requested procs : 8\n",
      "Max procs available: 16\n",
      "Time taken for the parallel for loop: 513.12 seconds\n",
      "\n",
      "   Time: 522.1245 seconds\n",
      "   Speedup over Python: 5.83x\n"
     ]
    }
   ],
   "source": [
    "# Performance comparison framework\n",
    "def benchmark_all_methods(sparse_matrix, num_threads=16):\n",
    "    \"\"\"\n",
    "    Compare all mutual information computation methods\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    print(\"Benchmarking different MI computation methods...\")\n",
    "    print(f\"Matrix size: {sparse_matrix.shape}\")\n",
    "    print(f\"Density: {sparse_matrix.nnz / (sparse_matrix.shape[0] * sparse_matrix.shape[1]):.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # # 1. Pure Python (your original)\n",
    "    # print(\"1. Testing Python parallel implementation...\")\n",
    "    # start_time = time.time()\n",
    "    # mi_python = mutual_information_matrix_parallel(sparse_matrix, nbins=20, n_jobs=num_threads)\n",
    "    python_time = 3042.1938\n",
    "    # results['python_parallel'] = {'time': python_time, 'result': mi_python}\n",
    "    # print(f\"   Time: {python_time:.4f} seconds\")\n",
    "    \n",
    "    # 2. C++ via file I/O (if compiled)\n",
    "    try:\n",
    "        print(\"2. Testing C++ OpenMP with file I/O...\")\n",
    "        start_time = time.time()\n",
    "        mi_cpp = compute_mi_cpp_optimized(sparse_matrix, method=\"openmp\", num_threads=num_threads)\n",
    "        cpp_time = time.time() - start_time\n",
    "        results['cpp_openmp'] = {'time': cpp_time, 'result': mi_cpp}\n",
    "        print(f\"   Time: {cpp_time:.4f} seconds\")\n",
    "        \n",
    "        # Calculate speedup\n",
    "        speedup = python_time / cpp_time\n",
    "        print(f\"   Speedup over Python: {speedup:.2f}x\")\n",
    "        \n",
    "        # # Calculate accuracy\n",
    "        # error = np.sqrt(np.mean((mi_python - mi_cpp)**2))\n",
    "        # print(f\"   RMSE vs Python: {error:.6f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   C++ method failed: {e}\")\n",
    "    \n",
    "    # # 3. DataFrame method\n",
    "    # print(\"3. Testing DataFrame method...\")\n",
    "    # dense_matrix = sparse_matrix.toarray().T\n",
    "    # df = pd.DataFrame(dense_matrix)\n",
    "    # start_time = time.time()\n",
    "    # mi_df = mutual_information_matrix_df(df, bins=20, n_jobs=num_threads)\n",
    "    # df_time = time.time() - start_time\n",
    "    # results['dataframe'] = {'time': df_time, 'result': mi_df}\n",
    "    # print(f\"   Time: {df_time:.4f} seconds\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test with your current matrix\n",
    "print(\"Ready to benchmark - uncomment the line below to run:\")\n",
    "benchmark_results = benchmark_all_methods(sparse_matrix, num_threads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import py_mi_openmp as cpp_imp\n",
    "\n",
    "cpp_imp.run()\n",
    "print(cpp_imp.add(2, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dwave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
